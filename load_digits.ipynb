{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_digits()\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 8, 8)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1437, 64), (360, 64), (1437, 10), (360, 10))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.data\n",
    "Y = dataset.target\n",
    "Y = np.eye(10)[Y]  #one hot #  [Y]: به عنوان اندیس آی (10) استفاده میشود\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    return 1 / (1 + np.exp(-X))\n",
    "\n",
    "def softmax(X):  #در شبکه عصبی که مسیله کلاسیفیکیشین باشد لایه ی آخر از سافتمکس استفاده میشود \n",
    "    return np.exp(X) / np.sum(np.exp(X))\n",
    "\n",
    "def root_mean_squired_error(Y_gt, Y_pred):\n",
    "    return np.sqrt(np.mean((Y_gt - Y_pred) ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 80\n",
    "η = 0.001  # learning rate\n",
    "\n",
    "D_in = X_train.shape[1]  # 64 #لایه ورودی\n",
    "H1 = 128  # لایه پنهان اول\n",
    "H2 = 32   # لایه پنهان دوم\n",
    "D_out = Y_train.shape[1]  # 10  # لایه خروجی"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.random.randn(D_in, H1)  #ماتریس اتصالات\n",
    "W2 = np.random.randn(H1, H2) \n",
    "W3 = np.random.randn(H2, D_out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "B1 = np.random.randn(1, H1)  \n",
    "B2 = np.random.randn(1, H2)\n",
    "B3 = np.random.randn(1, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train: 0.3366298641512468\n",
      "accuracy_train: 0.10508002783576896\n",
      "loss_test: 0.31396808319408187\n",
      "accuracy_test: 0.15833333333333333\n",
      "loss_train: 0.3000158301491934\n",
      "accuracy_train: 0.23312456506610996\n",
      "loss_test: 0.2913894444190616\n",
      "accuracy_test: 0.2972222222222222\n",
      "loss_train: 0.278458003709141\n",
      "accuracy_train: 0.360473208072373\n",
      "loss_test: 0.27497377352019364\n",
      "accuracy_test: 0.4083333333333333\n",
      "loss_train: 0.2604956629554922\n",
      "accuracy_train: 0.49269311064718163\n",
      "loss_test: 0.2608534292737929\n",
      "accuracy_test: 0.5305555555555556\n",
      "loss_train: 0.24707423446940593\n",
      "accuracy_train: 0.5553235908141962\n",
      "loss_test: 0.2502976372873518\n",
      "accuracy_test: 0.5666666666666667\n",
      "loss_train: 0.23499865703313572\n",
      "accuracy_train: 0.6137787056367432\n",
      "loss_test: 0.2418258009646612\n",
      "accuracy_test: 0.5888888888888889\n",
      "loss_train: 0.22503572414921447\n",
      "accuracy_train: 0.6687543493389004\n",
      "loss_test: 0.23448709357963823\n",
      "accuracy_test: 0.6111111111111112\n",
      "loss_train: 0.2160673898336548\n",
      "accuracy_train: 0.7028531663187195\n",
      "loss_test: 0.22808383837553875\n",
      "accuracy_test: 0.6444444444444445\n",
      "loss_train: 0.20813275715299848\n",
      "accuracy_train: 0.732776617954071\n",
      "loss_test: 0.22265942799137417\n",
      "accuracy_test: 0.6583333333333333\n",
      "loss_train: 0.2018369576260102\n",
      "accuracy_train: 0.7487821851078637\n",
      "loss_test: 0.21740595259254583\n",
      "accuracy_test: 0.6666666666666666\n",
      "loss_train: 0.19534680536354665\n",
      "accuracy_train: 0.767571329157968\n",
      "loss_test: 0.21249428346987442\n",
      "accuracy_test: 0.6777777777777778\n",
      "loss_train: 0.18948341690773957\n",
      "accuracy_train: 0.7835768963117606\n",
      "loss_test: 0.2075226123113665\n",
      "accuracy_test: 0.7055555555555556\n",
      "loss_train: 0.18391742754551263\n",
      "accuracy_train: 0.8016701461377871\n",
      "loss_test: 0.20247935148157276\n",
      "accuracy_test: 0.7138888888888889\n",
      "loss_train: 0.1786096709173446\n",
      "accuracy_train: 0.813500347947112\n",
      "loss_test: 0.19837969808924288\n",
      "accuracy_test: 0.7222222222222222\n",
      "loss_train: 0.17374036851593053\n",
      "accuracy_train: 0.825330549756437\n",
      "loss_test: 0.1946844740812301\n",
      "accuracy_test: 0.7361111111111112\n",
      "loss_train: 0.1690636047262985\n",
      "accuracy_train: 0.8343771746694503\n",
      "loss_test: 0.19094122539565878\n",
      "accuracy_test: 0.7555555555555555\n",
      "loss_train: 0.16447942621401268\n",
      "accuracy_train: 0.8427279053583855\n",
      "loss_test: 0.1877612593253264\n",
      "accuracy_test: 0.7583333333333333\n",
      "loss_train: 0.16013116046583953\n",
      "accuracy_train: 0.8559498956158664\n",
      "loss_test: 0.18461804701661685\n",
      "accuracy_test: 0.7611111111111111\n",
      "loss_train: 0.1558688339957644\n",
      "accuracy_train: 0.8663883089770354\n",
      "loss_test: 0.18164450486773906\n",
      "accuracy_test: 0.7666666666666667\n",
      "loss_train: 0.15185965858673323\n",
      "accuracy_train: 0.871955462769659\n",
      "loss_test: 0.17889430547843055\n",
      "accuracy_test: 0.7777777777777778\n",
      "loss_train: 0.14801798051783444\n",
      "accuracy_train: 0.8740431454418929\n",
      "loss_test: 0.17624824539924253\n",
      "accuracy_test: 0.7972222222222223\n",
      "loss_train: 0.14423473949048807\n",
      "accuracy_train: 0.883785664578984\n",
      "loss_test: 0.17387442092299965\n",
      "accuracy_test: 0.8055555555555556\n",
      "loss_train: 0.14056364434074367\n",
      "accuracy_train: 0.8921363952679193\n",
      "loss_test: 0.17178721923370968\n",
      "accuracy_test: 0.8083333333333333\n",
      "loss_train: 0.1370755150123337\n",
      "accuracy_train: 0.8963117606123869\n",
      "loss_test: 0.16982428921497214\n",
      "accuracy_test: 0.825\n",
      "loss_train: 0.1337713286913774\n",
      "accuracy_train: 0.9018789144050104\n",
      "loss_test: 0.16798194903211697\n",
      "accuracy_test: 0.8277777777777777\n",
      "loss_train: 0.13058258082056035\n",
      "accuracy_train: 0.9116214335421016\n",
      "loss_test: 0.16663620378520488\n",
      "accuracy_test: 0.8277777777777777\n",
      "loss_train: 0.12754815775050807\n",
      "accuracy_train: 0.9164926931106472\n",
      "loss_test: 0.16515846003946624\n",
      "accuracy_test: 0.8305555555555556\n",
      "loss_train: 0.12474641972784013\n",
      "accuracy_train: 0.9234516353514266\n",
      "loss_test: 0.16340578381865334\n",
      "accuracy_test: 0.8305555555555556\n",
      "loss_train: 0.12208799231881641\n",
      "accuracy_train: 0.9283228949199722\n",
      "loss_test: 0.16159066822442314\n",
      "accuracy_test: 0.8388888888888889\n",
      "loss_train: 0.11954117675829563\n",
      "accuracy_train: 0.929714683368128\n",
      "loss_test: 0.1598437665426819\n",
      "accuracy_test: 0.8388888888888889\n",
      "loss_train: 0.11711007586649215\n",
      "accuracy_train: 0.9324982602644398\n",
      "loss_test: 0.15826157282469644\n",
      "accuracy_test: 0.8388888888888889\n",
      "loss_train: 0.11478299709438312\n",
      "accuracy_train: 0.9366736256089074\n",
      "loss_test: 0.15678363751746713\n",
      "accuracy_test: 0.8416666666666667\n",
      "loss_train: 0.11247784541573647\n",
      "accuracy_train: 0.940848990953375\n",
      "loss_test: 0.15538294197792396\n",
      "accuracy_test: 0.8444444444444444\n",
      "loss_train: 0.11025274581823731\n",
      "accuracy_train: 0.942936673625609\n",
      "loss_test: 0.15410071364871913\n",
      "accuracy_test: 0.85\n",
      "loss_train: 0.10814195281044446\n",
      "accuracy_train: 0.9478079331941545\n",
      "loss_test: 0.15293396390082403\n",
      "accuracy_test: 0.85\n",
      "loss_train: 0.1061688988842075\n",
      "accuracy_train: 0.9491997216423104\n",
      "loss_test: 0.15179102268026812\n",
      "accuracy_test: 0.85\n",
      "loss_train: 0.10434488226668863\n",
      "accuracy_train: 0.9505915100904663\n",
      "loss_test: 0.15071685200868823\n",
      "accuracy_test: 0.8611111111111112\n",
      "loss_train: 0.10261773213880851\n",
      "accuracy_train: 0.954070981210856\n",
      "loss_test: 0.1497299387635835\n",
      "accuracy_test: 0.8611111111111112\n",
      "loss_train: 0.10095820782958023\n",
      "accuracy_train: 0.9547668754349339\n",
      "loss_test: 0.14880056436618866\n",
      "accuracy_test: 0.8638888888888889\n",
      "loss_train: 0.09935130429066805\n",
      "accuracy_train: 0.9561586638830898\n",
      "loss_test: 0.1479088313123285\n",
      "accuracy_test: 0.8694444444444445\n",
      "loss_train: 0.09780183126493863\n",
      "accuracy_train: 0.9582463465553236\n",
      "loss_test: 0.14701688312692326\n",
      "accuracy_test: 0.8694444444444445\n",
      "loss_train: 0.09631711144913885\n",
      "accuracy_train: 0.9610299234516354\n",
      "loss_test: 0.14612365839131852\n",
      "accuracy_test: 0.8694444444444445\n",
      "loss_train: 0.09489452553577189\n",
      "accuracy_train: 0.9617258176757133\n",
      "loss_test: 0.1452730490175298\n",
      "accuracy_test: 0.8694444444444445\n",
      "loss_train: 0.09352222939243579\n",
      "accuracy_train: 0.9617258176757133\n",
      "loss_test: 0.14448632569347214\n",
      "accuracy_test: 0.8694444444444445\n",
      "loss_train: 0.09220060435271872\n",
      "accuracy_train: 0.9624217118997912\n",
      "loss_test: 0.1437281533378032\n",
      "accuracy_test: 0.8694444444444445\n",
      "loss_train: 0.09093582985501082\n",
      "accuracy_train: 0.964509394572025\n",
      "loss_test: 0.14297690572116234\n",
      "accuracy_test: 0.8694444444444445\n",
      "loss_train: 0.08972973066013401\n",
      "accuracy_train: 0.965205288796103\n",
      "loss_test: 0.1422217156977714\n",
      "accuracy_test: 0.8722222222222222\n",
      "loss_train: 0.08855106024475724\n",
      "accuracy_train: 0.9672929714683368\n",
      "loss_test: 0.14144536420299925\n",
      "accuracy_test: 0.8722222222222222\n",
      "loss_train: 0.08736634045776012\n",
      "accuracy_train: 0.9672929714683368\n",
      "loss_test: 0.14066010288837666\n",
      "accuracy_test: 0.875\n",
      "loss_train: 0.0862387546120542\n",
      "accuracy_train: 0.9672929714683368\n",
      "loss_test: 0.13994417677916213\n",
      "accuracy_test: 0.8777777777777778\n",
      "loss_train: 0.08514026837046541\n",
      "accuracy_train: 0.9672929714683368\n",
      "loss_test: 0.13924727377420315\n",
      "accuracy_test: 0.8805555555555555\n",
      "loss_train: 0.08407190288860589\n",
      "accuracy_train: 0.9679888656924147\n",
      "loss_test: 0.13849949690053265\n",
      "accuracy_test: 0.8805555555555555\n",
      "loss_train: 0.08302471379705853\n",
      "accuracy_train: 0.9679888656924147\n",
      "loss_test: 0.13770031642840783\n",
      "accuracy_test: 0.8861111111111111\n",
      "loss_train: 0.08199271938571831\n",
      "accuracy_train: 0.9679888656924147\n",
      "loss_test: 0.13689082422958682\n",
      "accuracy_test: 0.8861111111111111\n",
      "loss_train: 0.08100119859505601\n",
      "accuracy_train: 0.9693806541405706\n",
      "loss_test: 0.13610854103282408\n",
      "accuracy_test: 0.8861111111111111\n",
      "loss_train: 0.08004251361837816\n",
      "accuracy_train: 0.9693806541405706\n",
      "loss_test: 0.13535588666530907\n",
      "accuracy_test: 0.8888888888888888\n",
      "loss_train: 0.0791165517019738\n",
      "accuracy_train: 0.9700765483646486\n",
      "loss_test: 0.13462454109795385\n",
      "accuracy_test: 0.8888888888888888\n",
      "loss_train: 0.07821835861331473\n",
      "accuracy_train: 0.9721642310368824\n",
      "loss_test: 0.1339047714577081\n",
      "accuracy_test: 0.8888888888888888\n",
      "loss_train: 0.07734216542193219\n",
      "accuracy_train: 0.9728601252609603\n",
      "loss_test: 0.13318468889665608\n",
      "accuracy_test: 0.8861111111111111\n",
      "loss_train: 0.07648624708683074\n",
      "accuracy_train: 0.9749478079331941\n",
      "loss_test: 0.132455724168005\n",
      "accuracy_test: 0.8861111111111111\n",
      "loss_train: 0.07564663094140849\n",
      "accuracy_train: 0.9756437021572721\n",
      "loss_test: 0.13171157367598563\n",
      "accuracy_test: 0.8861111111111111\n",
      "loss_train: 0.07481883516622628\n",
      "accuracy_train: 0.97633959638135\n",
      "loss_test: 0.13097133875681025\n",
      "accuracy_test: 0.8861111111111111\n",
      "loss_train: 0.07400772342865948\n",
      "accuracy_train: 0.977731384829506\n",
      "loss_test: 0.1302924167934013\n",
      "accuracy_test: 0.8861111111111111\n",
      "loss_train: 0.07322181675453268\n",
      "accuracy_train: 0.977731384829506\n",
      "loss_test: 0.12967168656899813\n",
      "accuracy_test: 0.8916666666666667\n",
      "loss_train: 0.07245693641684078\n",
      "accuracy_train: 0.977731384829506\n",
      "loss_test: 0.12908910934602083\n",
      "accuracy_test: 0.8972222222222223\n",
      "loss_train: 0.0717066639153209\n",
      "accuracy_train: 0.977731384829506\n",
      "loss_test: 0.12852848976476197\n",
      "accuracy_test: 0.9\n",
      "loss_train: 0.07097306823610205\n",
      "accuracy_train: 0.9791231732776617\n",
      "loss_test: 0.12797545904396523\n",
      "accuracy_test: 0.9\n",
      "loss_train: 0.07025909893596126\n",
      "accuracy_train: 0.9791231732776617\n",
      "loss_test: 0.1274288756137543\n",
      "accuracy_test: 0.9027777777777778\n",
      "loss_train: 0.06956318876392137\n",
      "accuracy_train: 0.9791231732776617\n",
      "loss_test: 0.12688982581665614\n",
      "accuracy_test: 0.9027777777777778\n",
      "loss_train: 0.06888184501012377\n",
      "accuracy_train: 0.9805149617258176\n",
      "loss_test: 0.1263599789730583\n",
      "accuracy_test: 0.9055555555555556\n",
      "loss_train: 0.06821133278879118\n",
      "accuracy_train: 0.9812108559498957\n",
      "loss_test: 0.12584095469479772\n",
      "accuracy_test: 0.9055555555555556\n",
      "loss_train: 0.06754941912722691\n",
      "accuracy_train: 0.9812108559498957\n",
      "loss_test: 0.12533378819313232\n",
      "accuracy_test: 0.9055555555555556\n",
      "loss_train: 0.0668964154105927\n",
      "accuracy_train: 0.9819067501739736\n",
      "loss_test: 0.12483895496122115\n",
      "accuracy_test: 0.9055555555555556\n",
      "loss_train: 0.0662544214016451\n",
      "accuracy_train: 0.9826026443980515\n",
      "loss_test: 0.12435618200345175\n",
      "accuracy_test: 0.9055555555555556\n",
      "loss_train: 0.06562564848186457\n",
      "accuracy_train: 0.9826026443980515\n",
      "loss_test: 0.12388411374213348\n",
      "accuracy_test: 0.9055555555555556\n",
      "loss_train: 0.06501129226878942\n",
      "accuracy_train: 0.9826026443980515\n",
      "loss_test: 0.1234202791574995\n",
      "accuracy_test: 0.9055555555555556\n",
      "loss_train: 0.06441100772364824\n",
      "accuracy_train: 0.9832985386221295\n",
      "loss_test: 0.12296133582275692\n",
      "accuracy_test: 0.9055555555555556\n",
      "loss_train: 0.06382229270035844\n",
      "accuracy_train: 0.9846903270702854\n",
      "loss_test: 0.12250312846882647\n",
      "accuracy_test: 0.9083333333333333\n",
      "loss_train: 0.06323872247907798\n",
      "accuracy_train: 0.9853862212943633\n",
      "loss_test: 0.12204071534084769\n",
      "accuracy_test: 0.9083333333333333\n",
      "loss_train: 0.06265029393403294\n",
      "accuracy_train: 0.9853862212943633\n",
      "loss_test: 0.12157449760282418\n",
      "accuracy_test: 0.9083333333333333\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "#train\n",
    "    Y_pred = []\n",
    "    for x, y in zip(X_train, Y_train):\n",
    "        x = x.reshape(-1, 1)\n",
    "        # forward\n",
    "\n",
    "        #layer 1\n",
    "        out1 = sigmoid(x.T @ W1 + B1)\n",
    "\n",
    "        #layer 2\n",
    "        out2 = sigmoid(out1 @ W2 + B2)\n",
    "\n",
    "        #layer 3\n",
    "        out3 = softmax(out2 @ W3 + B3)\n",
    "        y_pred = out3\n",
    "        Y_pred.append(y_pred)\n",
    "\n",
    "        loss = root_mean_squired_error(y, y_pred)\n",
    "\n",
    "        # backward     #باید همش مشتق بگیریم\n",
    "\n",
    "        #layer 3\n",
    "        error = -2 * (y - y_pred) # مشتق root_mean_squired_error\n",
    "        grad_B3 = error\n",
    "        grad_W3 = out2.T @ error\n",
    "\n",
    "        #layer 2\n",
    "        error = error @ W3.T * out2 * (1 - out2) # مشتق سیگموید : out2 * (1 - out2)\n",
    "        grad_B2 = error\n",
    "        grad_W2 = out1.T @ error\n",
    "\n",
    "        #layer 1\n",
    "        error = error @ W2.T * out1*(1 - out1) \n",
    "        grad_B1 = error\n",
    "        grad_W1 = x @ error\n",
    "\n",
    "        # update\n",
    "\n",
    "        #layer 1\n",
    "        W1 -= η * grad_W1\n",
    "        B1 -= η * grad_B1\n",
    "\n",
    "        #layer 2\n",
    "        W2 -= η * grad_W2\n",
    "        B2 -= η * grad_B2\n",
    "\n",
    "        #layer 3\n",
    "        W3 -= η * grad_W3\n",
    "        B3 -= η * grad_B3\n",
    "\n",
    "    Y_pred = np.array(Y_pred).reshape(-1, 10)   \n",
    "    loss_train = root_mean_squired_error(Y_train, Y_pred)\n",
    "    accuracy_train = np.sum(np.argmax(Y_train, axis=1) == np.argmax(Y_pred, axis=1)) / len(Y_train)\n",
    "    \n",
    "    print(\"loss_train:\", loss_train)\n",
    "    print(\"accuracy_train:\", accuracy_train)\n",
    "\n",
    "      # test\n",
    "\n",
    "    Y_pred = []\n",
    "    for x, y in zip(X_test, Y_test):\n",
    "\n",
    "        # forward\n",
    "        x = x.reshape(-1, 1)\n",
    "\n",
    "        # layer 1\n",
    "        net1 = x.T @ W1 + B1\n",
    "        out1 = sigmoid(net1)\n",
    "\n",
    "        # layer 2\n",
    "        net2 = out1 @ W2 + B2\n",
    "        out2 = sigmoid(net2)\n",
    "\n",
    "        # layer 3\n",
    "        net3 = out2 @ W3 + B3\n",
    "        out3 = softmax(net3)\n",
    "\n",
    "        y_pred = out3\n",
    "        Y_pred.append(y_pred.T)\n",
    "\n",
    "    Y_pred = np.array(Y_pred).reshape(-1, 10)\n",
    "    loss_test = root_mean_squired_error(Y_pred, Y_test)\n",
    "    accuracy_test = np.mean(np.argmax(Y_pred, axis=1) == np.argmax(Y_test, axis=1))\n",
    "\n",
    "    print(\"loss_test:\", loss_test)\n",
    "    print(\"accuracy_test:\", accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"4.png\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "image = image.astype(np.float32)\n",
    "\n",
    "x = image.reshape(-1, 1)\n",
    "\n",
    "# layer 1\n",
    "net1 = x.T @ W1 + B1\n",
    "out1 = sigmoid(net1)\n",
    "\n",
    "# layer 2\n",
    "net2 = out1 @ W2 + B2\n",
    "out2 = sigmoid(net2)\n",
    "\n",
    "# layer 3\n",
    "net3 = out2 @ W3 + B3\n",
    "out3 = softmax(net3)\n",
    "\n",
    "y_pred = out3\n",
    "print(np.argmax(y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
